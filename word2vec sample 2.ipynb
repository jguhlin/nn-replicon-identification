{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# Pretty much translating my clojure directly into python here...\n",
    "\n",
    "# k-mer size to use\n",
    "k = 9\n",
    "\n",
    "#\n",
    "# NOTE!!!!!!!!!!!!!!!!\n",
    "#\n",
    "# We can reduce problem space if we get the reverse complement, and add a bit to indicate reversed or not...\n",
    "#\n",
    "# Also -- Build a recurrent network to predict sequences that come after a given kmer?\n",
    "# Look at word2vec, dna2vec, bag of words, skip-gram\n",
    "#\n",
    "\n",
    "\n",
    "# Problem space\n",
    "space = 5 ** k\n",
    "\n",
    "def partition(n, step, coll):\n",
    "    for i in range(0, len(coll), step):\n",
    "        if (i+n > len(coll)):\n",
    "            break #  raise StopIteration...\n",
    "        yield coll[i:i+n]\n",
    "        \n",
    "def get_kmers(k):\n",
    "    return lambda sequence: partition(k, 1, sequence)\n",
    "\n",
    "def convert_nt(c):\n",
    "    return {\"N\": 0, \"A\": 1, \"C\": 2, \"T\": 3, \"G\": 4}.get(c, 0)\n",
    "\n",
    "def convert_kmer_to_int(kmer):\n",
    "    return int(''.join(str(x) for x in (map(convert_nt, kmer))), 5)\n",
    "\n",
    "# Sequences should be 1000bp in length, but will be multipled appropriately...\n",
    "# This is not the best behavior, but it is what exists...\n",
    "def convert_to_sparse_matrix_previous(sequence):\n",
    "    c = Counter(map(convert_kmer_to_int, get_kmers(k)(sequence)))\n",
    "    length = len(sequence)\n",
    "    lmul = 1000 / length # If length isn't 1000, multiple by some number to bring scores closer to expected\n",
    "                         # Because of how sparse this matrix is, I don't think this will actually help much...\n",
    "    return csr_matrix([c.get(x, 0) for x in range(0, space)]) * lmul\n",
    "    \n",
    "# Sequences should be 1000bp in length, but will be multipled appropriately...\n",
    "# This is not the best behavior, but it is what exists...\n",
    "def convert_to_sparse_matrix(sequence):\n",
    "    c = Counter(map(convert_kmer_to_int, get_kmers(k)(sequence)))\n",
    "    length = len(sequence)\n",
    "    lmul = 1000 / length # If length isn't 1000, multiple by some number to bring scores closer to expected\n",
    "                         # Because of how sparse this matrix is, I don't think this will actually help much...\n",
    "    cmat = csr_matrix([c.get(x, 0) for x in range(0, space)]) * lmul\n",
    "    coo = cmat.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "    \n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
