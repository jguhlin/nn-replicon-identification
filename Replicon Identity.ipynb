{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "import collections\n",
    "import random\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import concurrent.futures\n",
    "import functools\n",
    "from functools import partial\n",
    "import math\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "from random import shuffle\n",
    "import pickle\n",
    "import tempfile\n",
    "import ntpath\n",
    "import os.path\n",
    "\n",
    "# k-mer size to use\n",
    "k = 9\n",
    "\n",
    "#\n",
    "# NOTE!!!!!!!!!!!!!!!!\n",
    "#\n",
    "# We can reduce problem space if we get the reverse complement, and add a bit to indicate reversed or not...\n",
    "# Not really.... revcomp just doubles it back up again....\n",
    "#\n",
    "# Also -- Build a recurrent network to predict sequences that come after a given kmer?\n",
    "# Look at word2vec, dna2vec, bag of words, skip-gram\n",
    "#\n",
    "\n",
    "# Problem space\n",
    "space = 5 ** k\n",
    "\n",
    "def partition(n, step, coll):\n",
    "    for i in range(0, len(coll), step):\n",
    "        if (i+n > len(coll)):\n",
    "            break #  raise StopIteration...\n",
    "        yield coll[i:i+n]\n",
    "        \n",
    "def get_kmers(k):\n",
    "    return lambda sequence: partition(k, k, sequence)\n",
    "\n",
    "def convert_nt(c):\n",
    "    return {\"N\": 0, \"A\": 1, \"C\": 2, \"T\": 3, \"G\": 4}.get(c, 0)\n",
    "\n",
    "def convert_nt_complement(c):\n",
    "    return {\"N\": 0, \"A\": 3, \"C\": 4, \"T\": 1, \"G\": 2}.get(c, 0)\n",
    "\n",
    "def convert_kmer_to_int(kmer):\n",
    "    return int(''.join(str(x) for x in (map(convert_nt, kmer))), 5)\n",
    "\n",
    "def convert_kmer_to_int_complement(kmer):\n",
    "    return int(''.join(str(x) for x in reversed(list(map(convert_nt_complement, kmer)))), 5)\n",
    "\n",
    "def convert_base5(n):\n",
    "    return {\"0\": \"N\", \"1\": \"A\", \"2\": \"C\", \"3\": \"T\", \"4\": \"G\"}.get(n,\"N\")\n",
    "\n",
    "def convert_to_kmer(kmer):\n",
    "    return ''.join(map(convert_base5, str(np.base_repr(kmer, 5))))\n",
    "\n",
    "# Not using sparse tensors anymore.\n",
    "   \n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Get all kmers, in order, with a sliding window of k (but sliding 1bp for each iteration up to k)\n",
    "# Also get RC for all....\n",
    "\n",
    "def kmer_processor(seq,offset):\n",
    "    return list(map(convert_kmer_to_int, get_kmers(k)(seq[offset:])))\n",
    "\n",
    "def get_kmers_from_seq(sequence):\n",
    "    kmers_from_seq = list()\n",
    "\n",
    "    kp = functools.partial(kmer_processor, sequence)\n",
    "    \n",
    "    for i in map(kp, range(0,k)):\n",
    "        kmers_from_seq.append(i)\n",
    "\n",
    "    rev = sequence[::-1]\n",
    "    kpr = functools.partial(kmer_processor, rev)\n",
    "    \n",
    "    for i in map(kpr, range(0,k)):\n",
    "        kmers_from_seq.append(i)\n",
    "            \n",
    "#    for i in range(0,k):\n",
    "#        kmers_from_seq.append(kmer_processor(sequence,i))\n",
    "#    for i in range(0,k):\n",
    "#        kmers_from_seq.append(kmer_processor(rev, i))\n",
    "    return kmers_from_seq\n",
    "\n",
    "data = list()\n",
    "\n",
    "def load_fasta(filename):\n",
    "    data = dict()\n",
    "    file_base_name = ntpath.basename(filename)\n",
    "    picklefilename = file_base_name + \".picklepickle\"\n",
    "    if os.path.isfile(picklefilename):\n",
    "        print(\"Loading from pickle\")\n",
    "        data = pickle.load(open(picklefilename, \"rb\"))\n",
    "    else:\n",
    "        print(\"File not found, generating new sequence: \" + picklefilename)\n",
    "        for seq_record in SeqIO.parse(filename, \"fasta\"):\n",
    "            data.update({seq_record.id:\n",
    "                         get_kmers_from_seq(seq_record.seq.upper())})\n",
    "        pickle.dump(data, open(picklefilename, \"wb\"))\n",
    "    return(data)\n",
    "        \n",
    "def get_kmers_from_file(filename):\n",
    "    kmer_list = list()\n",
    "    for seq_record in SeqIO.parse(filename, \"fasta\"):\n",
    "        kmer_list.extend(get_kmers_from_seq(seq_record.seq.upper()))\n",
    "    return set([item for sublist in kmer_list for item in sublist])\n",
    "\n",
    "all_kmers = set()\n",
    "\n",
    "# Very slow, should make this part concurrent...\n",
    "\n",
    "def find_all_kmers(directory):\n",
    "    kmer_master_list = list()\n",
    "    files = [directory + \"/\" + f for f in os.listdir(directory)]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        for i in executor.map(get_kmers_from_file, files):\n",
    "            kmer_master_list.extend(list(i))\n",
    "            kmer_master_list = list(set(kmer_master_list))\n",
    "            print(\"Total unique kmers: \" + str(len(set(kmer_master_list))))\n",
    "    return set(kmer_master_list)\n",
    "\n",
    "def get_categories(directory):\n",
    "    data = list()\n",
    "    files = os.listdir(directory)\n",
    "    for filename in files:\n",
    "        for seq_record in SeqIO.parse(directory + \"/\" + filename, \"fasta\"):\n",
    "            data.append(seq_record.id)\n",
    "    data = sorted(list(set(data)))\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found, generating new sequence: KH46c.final.fasta.picklepickle\n"
     ]
    }
   ],
   "source": [
    "filegen = training_file_generator(\"training-files/\")\n",
    "training_data = load_fasta(filegen())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replicons_list = get_categories(\"training-files/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269132"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because this was run at work on a smaller sample of files....\n",
    "# with open(\"all_kmers_subset.txt\", \"w\") as f:\n",
    "#     for s in all_kmers:\n",
    "#         f.write(str(s) +\"\\n\")\n",
    "\n",
    "# Because this was run at work on a smaller sample of files....\n",
    "all_kmers = list()\n",
    "# with open(\"all_kmers_subset.txt\", \"r\") as f:\n",
    "#     for line in f:\n",
    "#         all_kmers.append(int(line.strip()))\n",
    "\n",
    "all_kmers = pickle.load(open(\"all_kmers.p\", \"rb\"))\n",
    "\n",
    "all_kmers = set(all_kmers)\n",
    "len(all_kmers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[269132, 1683993, 1953125]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(data)\n",
    "\n",
    "# all_kmers = set([item for sublist in data for item in sublist])\n",
    "unused_kmers = set(range(0, space)) - all_kmers\n",
    "\n",
    "kmer_dict = dict()\n",
    "reverse_kmer_dict = dict();\n",
    "\n",
    "a = 0\n",
    "for i in all_kmers:\n",
    "    kmer_dict[i] = a\n",
    "    reverse_kmer_dict[a] = i\n",
    "    a += 1\n",
    "    \n",
    "kmer_count = len(all_kmers)\n",
    "\n",
    "[len(all_kmers), len(unused_kmers), space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training_file_generator(directory):\n",
    "    files = [directory + \"/\" + f for f in os.listdir(directory)]\n",
    "    random.shuffle(files)\n",
    "    def gen():\n",
    "        nonlocal files\n",
    "        if (len(files) == 0):\n",
    "            files = [directory + \"/\" + f for f in os.listdir(directory)]\n",
    "            random.shuffle(files)\n",
    "        return(files.pop())\n",
    "    return gen\n",
    "\n",
    "def gen_random_training_data(input_data, window_size):\n",
    "    rname = random.choice(list(input_data.keys()))\n",
    "    rdata = random.choice(input_data[rname])\n",
    "    idx = random.randrange(window_size + 1, len(rdata) - window_size - 1)\n",
    "    tdata = list();\n",
    "    for i in range(idx - window_size - 1, idx + window_size):\n",
    "        if (i < 0): continue\n",
    "        if (i >= len(rdata)): break\n",
    "        if type(rdata[idx]) == list: break;\n",
    "        if type(rdata[i]) == list: break\n",
    "        tdata.append(kmer_dict[rdata[i]])\n",
    "    return tdata, rname\n",
    "\n",
    "# The current state is, each training batch is from a single FASTA file (strain, usually)\n",
    "# This can be ok, as long as training batch is a large number\n",
    "# Need to speed up reading of FASTA files though, maybe pyfaidx or something?\n",
    "\n",
    "# Define the one-hot dictionary...\n",
    "\n",
    "oh = dict()\n",
    "a = 0\n",
    "for i in replicons_list:\n",
    "    oh[i] = tf.one_hot(a, len(replicons_list))\n",
    "    a += 1\n",
    "    \n",
    "oh = dict()\n",
    "a = 0\n",
    "for i in replicons_list:\n",
    "    oh[i] = a\n",
    "    a += 1\n",
    "    \n",
    "oh = dict()\n",
    "oh['Main'] = [1.0, 0.0, 0.0]\n",
    "oh['pSymA'] = [0.0, 1.0, 0.0]\n",
    "oh['pSymB'] = [0.0, 0.0, 1.0]\n",
    "\n",
    "\n",
    "def generate_training_batch(data, batch_size, window_size):\n",
    "    training_batch_data = list();\n",
    "    while len(training_batch_data) < batch_size:\n",
    "         training_batch_data.append(gen_random_training_data(data, \n",
    "                                                             window_size))\n",
    "    return training_batch_data\n",
    "\n",
    "def train_input_fn():\n",
    "    rdata = generate_training_batch(training_data, 1, window_size)[0]\n",
    "    return rdata[0], oh[rdata[1]]\n",
    "    # return {\"train_input\": rdata[0]}, oh[rdata[1]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([247872,\n",
       "  221046,\n",
       "  29443,\n",
       "  92155,\n",
       "  190386,\n",
       "  173423,\n",
       "  226297,\n",
       "  234312,\n",
       "  22989,\n",
       "  217994,\n",
       "  25037,\n",
       "  29510,\n",
       "  3023,\n",
       "  223617,\n",
       "  240546],\n",
       " [0.0, 0.0, 1.0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filegen = training_file_generator(\"training-files/\")\n",
    "\n",
    "# training_data = load_fasta(filegen())\n",
    "# training_data_backup = training_data\n",
    "\n",
    "# len(training_data)\n",
    "\n",
    "# gen_random_training_data(training_data, 7)\n",
    "\n",
    "# generate_training_batch(training_data, 5, 7)\n",
    "\n",
    "# random.choice(list(input_data.keys()))\n",
    "\n",
    "train_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105761,\n",
       " 49545,\n",
       " 256008,\n",
       " 139576,\n",
       " 51403,\n",
       " 244727,\n",
       " 259373,\n",
       " 264896,\n",
       " 262923,\n",
       " 16082,\n",
       " 261828,\n",
       " 140172,\n",
       " 49599,\n",
       " 30035,\n",
       " 29680]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filegen = training_file_generator(\"training-files/\")\n",
    "\n",
    "# training_data = load_fasta(filegen())\n",
    "\n",
    "batch_size = 1024\n",
    "embedding_size = 128\n",
    "window_size = 7\n",
    "\n",
    "validation_set = generate_training_batch(training_data, 10000, window_size)\n",
    "# validation_kmers = list(set([i[0] for i in validation_set]))\n",
    "# del validation_set\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 1024\n",
    "valid_examples = [i[0] for i in validation_set]\n",
    "num_sampled = 256\n",
    "del validation_set\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 500\n",
    "n_hidden_2 = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax:0' shape=(3,) dtype=int64>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(1, 3) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "with graph.as_default():\n",
    "    # Load embedding\n",
    "    kmers = tf.Variable(tf.constant(0.0, shape=[kmer_count, 128]),\n",
    "                       trainable=False, name=\"kmers\")\n",
    "\n",
    "    # embeddings = np.load(\"embeddings_200000.npy\")\n",
    "\n",
    "    embedding_placeholder = tf.placeholder(tf.int32, [kmer_count, 128])\n",
    "    embedding_init = kmers.assign(embeddings)\n",
    "\n",
    "    # Input data.\n",
    "    # Take 1 kmer and the 7 on each side of it\n",
    "    # So for k=9, we are testing 135bp\n",
    "    # So n = 15\n",
    "    train_input = tf.placeholder(tf.int32, shape=[batch_size, 15]) \n",
    "    train_label = tf.placeholder(tf.int32, shape=[batch_size, 3])\n",
    "#    train_label_r = tf.reshape(train_label, [-1])\n",
    "#    labels = tf.one_hot(train_label, len(replicons_list), dtype=tf.int32)\n",
    "\n",
    " \n",
    "    kmer_input = tf.nn.embedding_lookup(embeddings, train_input)\n",
    "    kmer_input_r = tf.reshape(kmer_input, [batch_size, -1]) # Flatten\n",
    "\n",
    "    # valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    # replicons = tf.placeholder(tf.int16, shape=[None, 1])\n",
    "\n",
    "    l1 = tf.layers.dense(kmer_input_r, n_hidden_1)\n",
    "    l2 = tf.layers.dense(l1, n_hidden_2)\n",
    "    logits = tf.layers.dense(l2, len(replicons_list))\n",
    "    \n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_prob = tf.nn.softmax(logits)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = train_label))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    acc = tf.metrics.accuracy(labels = tf.argmax(train_label, 1), predictions=pred_classes)\n",
    "    \n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([239238,\n",
       "  169260,\n",
       "  242754,\n",
       "  215856,\n",
       "  60843,\n",
       "  132808,\n",
       "  249405,\n",
       "  129105,\n",
       "  112336,\n",
       "  19860,\n",
       "  139171,\n",
       "  66831,\n",
       "  213222,\n",
       "  255357,\n",
       "  21515],\n",
       " [0.0, 0.0, 1.0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2], dtype=int64), array([[ 0.1505875 ,  0.2130429 ,  0.63636953]], dtype=float32)]   [0.0, 1.0, 0.0]\n",
      "[array([2], dtype=int64), array([[ 0.17296444,  0.41227347,  0.41476214]], dtype=float32)]   [0.0, 1.0, 0.0]\n",
      "[array([2], dtype=int64), array([[ 0.20260364,  0.31371108,  0.48368534]], dtype=float32)]   [1.0, 0.0, 0.0]\n",
      "[array([2], dtype=int64), array([[ 0.33472094,  0.28635615,  0.37892291]], dtype=float32)]   [1.0, 0.0, 0.0]\n",
      "[array([2], dtype=int64), array([[ 0.10926115,  0.29860041,  0.59213847]], dtype=float32)]   [0.0, 0.0, 1.0]\n",
      "[array([2], dtype=int64), array([[ 0.21947457,  0.25672138,  0.52380401]], dtype=float32)]   [0.0, 1.0, 0.0]\n",
      "[array([2], dtype=int64), array([[ 0.1778408 ,  0.30563816,  0.51652104]], dtype=float32)]   [1.0, 0.0, 0.0]\n",
      "[array([2], dtype=int64), array([[ 0.11665278,  0.31180292,  0.57154435]], dtype=float32)]   [1.0, 0.0, 0.0]\n",
      "[array([2], dtype=int64), array([[ 0.16575523,  0.3371191 ,  0.49712569]], dtype=float32)]   [1.0, 0.0, 0.0]\n",
      "[array([2], dtype=int64), array([[ 0.18270759,  0.1957254 ,  0.62156695]], dtype=float32)]   [0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "    init.run()\n",
    "    num_steps = 5000\n",
    "    for step in xrange(num_steps):\n",
    "      myt, label = train_input_fn()\n",
    "      train.run(feed_dict={train_input: [myt], \n",
    "                           train_label: [label]})\n",
    "    \n",
    "#    print(session.run([acc], feed_dict={train_input: [myt], train_label: [label]}))\n",
    "    \n",
    "    for step in xrange(10):\n",
    "        myt, label = train_input_fn()\n",
    "        classification = session.run([pred_classes, pred_prob], feed_dict={train_input: [myt]})\n",
    "        print(classification, \" \", label)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_input': <tf.Tensor 'embedding_lookup_12:0' shape=(15, 128) dtype=float32>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 5\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)\n",
    "future = executor.submit(load_fasta, filegen())\n",
    "\n",
    "tdata = list()\n",
    "tdata = future.result()\n",
    "print(\"tdata length: \", str(len(tdata)))\n",
    "\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "  # We must initialize all variables before we use them.\n",
    "  init.run()\n",
    "  print('Initialized')\n",
    "\n",
    "  average_loss = 0\n",
    "  for step in xrange(num_steps):\n",
    "    \n",
    "    if step % 15000 == 0: # Change files every 15k steps\n",
    "        print(\"Loading new file at step: \", step)\n",
    "        # Start loading the next file, so it has time to finish while the neural net does its training\n",
    "        tdata = future.result()\n",
    "        future = executor.submit(load_fasta, filegen())\n",
    "        \n",
    "    if step == 5:\n",
    "        print(\"Reached step 5!\")\n",
    "        \n",
    "    if len(tdata) == 0:\n",
    "        print(\"Using short-circuit load-fasta at step: \", step)\n",
    "        tdata = load_fasta(filegen()) # Emergency short-circuit here....\n",
    "        \n",
    "    batch_data = generate_training_batch(tdata, batch_size, window_size)\n",
    "    feed_dict = {train_inputs: [x[0] for x in batch_data], \n",
    "                 train_labels: [[x[1]] for x in batch_data]}\n",
    "\n",
    "    # We perform one update step by evaluating the optimizer op (including it\n",
    "    # in the list of returned values for session.run()\n",
    "    _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "    average_loss += loss_val\n",
    "\n",
    "    # Print status every 10k steps\n",
    "    if step % 10000 == 0:\n",
    "        if step > 0:\n",
    "            average_loss /= 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "        print('Average loss at step ', step, ': ', average_loss)\n",
    "        average_loss = 0\n",
    "    \n",
    "    # Save every 50k steps\n",
    "#    if step % 100000 == 0:\n",
    "#        print(\"Saving model at step: \", step)\n",
    "#        saver.save(session, './replicon-model', global_step=step)\n",
    "#        print(\"Saved model at step: \", step)\n",
    "\n",
    "        \n",
    "#    if step % 20000 == 0:\n",
    "#        sim = similarity.eval()\n",
    "#        accuracy = 0\n",
    "#        for i in range(0, 100):\n",
    "#            rand_kmer = random.choice(list(validation_dict.keys()))\n",
    "#            top_k = 10\n",
    "#            nearest = (-sim[rand_kmer, :]).argsort()[1:top_k + 1]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 11: 9,\n",
       " 12: 10,\n",
       " 13: 11,\n",
       " 14: 12,\n",
       " 16: 13,\n",
       " 17: 14,\n",
       " 18: 15,\n",
       " 19: 16,\n",
       " 21: 17,\n",
       " 22: 18,\n",
       " 23: 19,\n",
       " 24: 20,\n",
       " 31: 21,\n",
       " 32: 22,\n",
       " 33: 23,\n",
       " 34: 24,\n",
       " 36: 25,\n",
       " 37: 26,\n",
       " 38: 27,\n",
       " 39: 28,\n",
       " 41: 29,\n",
       " 42: 30,\n",
       " 43: 31,\n",
       " 44: 32,\n",
       " 46: 33,\n",
       " 47: 34,\n",
       " 48: 35,\n",
       " 49: 36,\n",
       " 56: 37,\n",
       " 57: 38,\n",
       " 58: 39,\n",
       " 59: 40,\n",
       " 61: 41,\n",
       " 62: 42,\n",
       " 63: 43,\n",
       " 64: 44,\n",
       " 66: 45,\n",
       " 67: 46,\n",
       " 68: 47,\n",
       " 69: 48,\n",
       " 71: 49,\n",
       " 72: 50,\n",
       " 73: 51,\n",
       " 74: 52,\n",
       " 81: 53,\n",
       " 82: 54,\n",
       " 83: 55,\n",
       " 84: 56,\n",
       " 86: 57,\n",
       " 87: 58,\n",
       " 88: 59,\n",
       " 89: 60,\n",
       " 91: 61,\n",
       " 92: 62,\n",
       " 93: 63,\n",
       " 94: 64,\n",
       " 96: 65,\n",
       " 97: 66,\n",
       " 98: 67,\n",
       " 99: 68,\n",
       " 106: 69,\n",
       " 107: 70,\n",
       " 108: 71,\n",
       " 109: 72,\n",
       " 111: 73,\n",
       " 112: 74,\n",
       " 113: 75,\n",
       " 114: 76,\n",
       " 116: 77,\n",
       " 117: 78,\n",
       " 118: 79,\n",
       " 119: 80,\n",
       " 121: 81,\n",
       " 122: 82,\n",
       " 123: 83,\n",
       " 124: 84,\n",
       " 156: 85,\n",
       " 158: 86,\n",
       " 159: 87,\n",
       " 161: 88,\n",
       " 162: 89,\n",
       " 163: 90,\n",
       " 164: 91,\n",
       " 166: 92,\n",
       " 168: 93,\n",
       " 169: 94,\n",
       " 171: 95,\n",
       " 172: 96,\n",
       " 173: 97,\n",
       " 174: 98,\n",
       " 181: 99,\n",
       " 182: 100,\n",
       " 183: 101,\n",
       " 184: 102,\n",
       " 186: 103,\n",
       " 187: 104,\n",
       " 188: 105,\n",
       " 189: 106,\n",
       " 191: 107,\n",
       " 192: 108,\n",
       " 194: 109,\n",
       " 196: 110,\n",
       " 197: 111,\n",
       " 199: 112,\n",
       " 207: 113,\n",
       " 208: 114,\n",
       " 209: 115,\n",
       " 212: 116,\n",
       " 213: 117,\n",
       " 214: 118,\n",
       " 216: 119,\n",
       " 217: 120,\n",
       " 218: 121,\n",
       " 221: 122,\n",
       " 222: 123,\n",
       " 223: 124,\n",
       " 231: 125,\n",
       " 232: 126,\n",
       " 233: 127,\n",
       " 234: 128,\n",
       " 236: 129,\n",
       " 237: 130,\n",
       " 238: 131,\n",
       " 239: 132,\n",
       " 241: 133,\n",
       " 242: 134,\n",
       " 243: 135,\n",
       " 244: 136,\n",
       " 246: 137,\n",
       " 247: 138,\n",
       " 248: 139,\n",
       " 281: 140,\n",
       " 282: 141,\n",
       " 283: 142,\n",
       " 284: 143,\n",
       " 286: 144,\n",
       " 287: 145,\n",
       " 288: 146,\n",
       " 289: 147,\n",
       " 291: 148,\n",
       " 292: 149,\n",
       " 293: 150,\n",
       " 294: 151,\n",
       " 296: 152,\n",
       " 297: 153,\n",
       " 298: 154,\n",
       " 299: 155,\n",
       " 306: 156,\n",
       " 307: 157,\n",
       " 309: 158,\n",
       " 311: 159,\n",
       " 312: 160,\n",
       " 313: 161,\n",
       " 314: 162,\n",
       " 316: 163,\n",
       " 317: 164,\n",
       " 318: 165,\n",
       " 319: 166,\n",
       " 321: 167,\n",
       " 322: 168,\n",
       " 323: 169,\n",
       " 324: 170,\n",
       " 331: 171,\n",
       " 332: 172,\n",
       " 333: 173,\n",
       " 334: 174,\n",
       " 336: 175,\n",
       " 337: 176,\n",
       " 338: 177,\n",
       " 339: 178,\n",
       " 342: 179,\n",
       " 343: 180,\n",
       " 344: 181,\n",
       " 346: 182,\n",
       " 347: 183,\n",
       " 348: 184,\n",
       " 356: 185,\n",
       " 357: 186,\n",
       " 359: 187,\n",
       " 361: 188,\n",
       " 362: 189,\n",
       " 363: 190,\n",
       " 364: 191,\n",
       " 366: 192,\n",
       " 367: 193,\n",
       " 368: 194,\n",
       " 369: 195,\n",
       " 371: 196,\n",
       " 372: 197,\n",
       " 373: 198,\n",
       " 374: 199,\n",
       " 406: 200,\n",
       " 407: 201,\n",
       " 409: 202,\n",
       " 411: 203,\n",
       " 412: 204,\n",
       " 413: 205,\n",
       " 414: 206,\n",
       " 416: 207,\n",
       " 417: 208,\n",
       " 418: 209,\n",
       " 419: 210,\n",
       " 421: 211,\n",
       " 422: 212,\n",
       " 423: 213,\n",
       " 432: 214,\n",
       " 433: 215,\n",
       " 437: 216,\n",
       " 438: 217,\n",
       " 439: 218,\n",
       " 441: 219,\n",
       " 442: 220,\n",
       " 443: 221,\n",
       " 444: 222,\n",
       " 446: 223,\n",
       " 447: 224,\n",
       " 448: 225,\n",
       " 449: 226,\n",
       " 457: 227,\n",
       " 458: 228,\n",
       " 459: 229,\n",
       " 461: 230,\n",
       " 462: 231,\n",
       " 463: 232,\n",
       " 464: 233,\n",
       " 466: 234,\n",
       " 467: 235,\n",
       " 468: 236,\n",
       " 469: 237,\n",
       " 471: 238,\n",
       " 472: 239,\n",
       " 473: 240,\n",
       " 474: 241,\n",
       " 481: 242,\n",
       " 482: 243,\n",
       " 483: 244,\n",
       " 487: 245,\n",
       " 488: 246,\n",
       " 489: 247,\n",
       " 491: 248,\n",
       " 492: 249,\n",
       " 493: 250,\n",
       " 494: 251,\n",
       " 496: 252,\n",
       " 497: 253,\n",
       " 499: 254,\n",
       " 531: 255,\n",
       " 532: 256,\n",
       " 533: 257,\n",
       " 534: 258,\n",
       " 536: 259,\n",
       " 537: 260,\n",
       " 538: 261,\n",
       " 539: 262,\n",
       " 541: 263,\n",
       " 542: 264,\n",
       " 543: 265,\n",
       " 544: 266,\n",
       " 546: 267,\n",
       " 547: 268,\n",
       " 548: 269,\n",
       " 549: 270,\n",
       " 556: 271,\n",
       " 557: 272,\n",
       " 558: 273,\n",
       " 559: 274,\n",
       " 561: 275,\n",
       " 562: 276,\n",
       " 563: 277,\n",
       " 564: 278,\n",
       " 566: 279,\n",
       " 567: 280,\n",
       " 568: 281,\n",
       " 569: 282,\n",
       " 571: 283,\n",
       " 572: 284,\n",
       " 573: 285,\n",
       " 574: 286,\n",
       " 582: 287,\n",
       " 583: 288,\n",
       " 584: 289,\n",
       " 586: 290,\n",
       " 587: 291,\n",
       " 588: 292,\n",
       " 589: 293,\n",
       " 591: 294,\n",
       " 592: 295,\n",
       " 593: 296,\n",
       " 594: 297,\n",
       " 596: 298,\n",
       " 597: 299,\n",
       " 598: 300,\n",
       " 599: 301,\n",
       " 606: 302,\n",
       " 607: 303,\n",
       " 608: 304,\n",
       " 609: 305,\n",
       " 611: 306,\n",
       " 612: 307,\n",
       " 613: 308,\n",
       " 614: 309,\n",
       " 616: 310,\n",
       " 617: 311,\n",
       " 618: 312,\n",
       " 619: 313,\n",
       " 621: 314,\n",
       " 622: 315,\n",
       " 623: 316,\n",
       " 624: 317,\n",
       " 781: 318,\n",
       " 782: 319,\n",
       " 784: 320,\n",
       " 794: 321,\n",
       " 796: 322,\n",
       " 797: 323,\n",
       " 798: 324,\n",
       " 806: 325,\n",
       " 811: 326,\n",
       " 812: 327,\n",
       " 814: 328,\n",
       " 819: 329,\n",
       " 823: 330,\n",
       " 824: 331,\n",
       " 831: 332,\n",
       " 832: 333,\n",
       " 833: 334,\n",
       " 843: 335,\n",
       " 844: 336,\n",
       " 846: 337,\n",
       " 857: 338,\n",
       " 859: 339,\n",
       " 861: 340,\n",
       " 863: 341,\n",
       " 864: 342,\n",
       " 866: 343,\n",
       " 867: 344,\n",
       " 868: 345,\n",
       " 871: 346,\n",
       " 872: 347,\n",
       " 906: 348,\n",
       " 909: 349,\n",
       " 911: 350,\n",
       " 912: 351,\n",
       " 917: 352,\n",
       " 922: 353,\n",
       " 923: 354,\n",
       " 932: 355,\n",
       " 934: 356,\n",
       " 936: 357,\n",
       " 939: 358,\n",
       " 942: 359,\n",
       " 943: 360,\n",
       " 944: 361,\n",
       " 946: 362,\n",
       " 949: 363,\n",
       " 957: 364,\n",
       " 958: 365,\n",
       " 964: 366,\n",
       " 972: 367,\n",
       " 981: 368,\n",
       " 982: 369,\n",
       " 984: 370,\n",
       " 987: 371,\n",
       " 988: 372,\n",
       " 996: 373,\n",
       " 997: 374,\n",
       " 999: 375,\n",
       " 1039: 376,\n",
       " 1042: 377,\n",
       " 1048: 378,\n",
       " 1049: 379,\n",
       " 1062: 380,\n",
       " 1064: 381,\n",
       " 1067: 382,\n",
       " 1071: 383,\n",
       " 1072: 384,\n",
       " 1073: 385,\n",
       " 1074: 386,\n",
       " 1082: 387,\n",
       " 1086: 388,\n",
       " 1092: 389,\n",
       " 1093: 390,\n",
       " 1094: 391,\n",
       " 1106: 392,\n",
       " 1108: 393,\n",
       " 1112: 394,\n",
       " 1113: 395,\n",
       " 1116: 396,\n",
       " 1117: 397,\n",
       " 1119: 398,\n",
       " 1159: 399,\n",
       " 1162: 400,\n",
       " 1164: 401,\n",
       " 1166: 402,\n",
       " 1167: 403,\n",
       " 1172: 404,\n",
       " 1173: 405,\n",
       " 1174: 406,\n",
       " 1182: 407,\n",
       " 1184: 408,\n",
       " 1189: 409,\n",
       " 1191: 410,\n",
       " 1193: 411,\n",
       " 1197: 412,\n",
       " 1198: 413,\n",
       " 1199: 414,\n",
       " 1209: 415,\n",
       " 1213: 416,\n",
       " 1217: 417,\n",
       " 1218: 418,\n",
       " 1222: 419,\n",
       " 1232: 420,\n",
       " 1236: 421,\n",
       " 1237: 422,\n",
       " 1238: 423,\n",
       " 1239: 424,\n",
       " 1244: 425,\n",
       " 1406: 426,\n",
       " 1407: 427,\n",
       " 1408: 428,\n",
       " 1412: 429,\n",
       " 1413: 430,\n",
       " 1416: 431,\n",
       " 1418: 432,\n",
       " 1421: 433,\n",
       " 1422: 434,\n",
       " 1423: 435,\n",
       " 1050000: 436,\n",
       " 1424: 437,\n",
       " 1431: 438,\n",
       " 1433: 439,\n",
       " 1437: 440,\n",
       " 1438: 441,\n",
       " 1439: 442,\n",
       " 1443: 443,\n",
       " 1446: 444,\n",
       " 1447: 445,\n",
       " 1449: 446,\n",
       " 1457: 447,\n",
       " 1458: 448,\n",
       " 1459: 449,\n",
       " 1461: 450,\n",
       " 1463: 451,\n",
       " 1464: 452,\n",
       " 1467: 453,\n",
       " 1472: 454,\n",
       " 1474: 455,\n",
       " 1481: 456,\n",
       " 1482: 457,\n",
       " 1486: 458,\n",
       " 1487: 459,\n",
       " 1488: 460,\n",
       " 1489: 461,\n",
       " 1491: 462,\n",
       " 1492: 463,\n",
       " 1493: 464,\n",
       " 1496: 465,\n",
       " 1499: 466,\n",
       " 1532: 467,\n",
       " 1534: 468,\n",
       " 1537: 469,\n",
       " 1538: 470,\n",
       " 1539: 471,\n",
       " 1546: 472,\n",
       " 1547: 473,\n",
       " 1557: 474,\n",
       " 1562: 475,\n",
       " 1567: 476,\n",
       " 1568: 477,\n",
       " 1569: 478,\n",
       " 1572: 479,\n",
       " 1574: 480,\n",
       " 1581: 481,\n",
       " 1584: 482,\n",
       " 1586: 483,\n",
       " 1587: 484,\n",
       " 1588: 485,\n",
       " 1589: 486,\n",
       " 1592: 487,\n",
       " 1593: 488,\n",
       " 1594: 489,\n",
       " 1596: 490,\n",
       " 1599: 491,\n",
       " 1606: 492,\n",
       " 1607: 493,\n",
       " 1609: 494,\n",
       " 1611: 495,\n",
       " 1612: 496,\n",
       " 1613: 497,\n",
       " 1614: 498,\n",
       " 1616: 499,\n",
       " 1617: 500,\n",
       " 1621: 501,\n",
       " 1622: 502,\n",
       " 1623: 503,\n",
       " 1624: 504,\n",
       " 1656: 505,\n",
       " 1659: 506,\n",
       " 1662: 507,\n",
       " 1666: 508,\n",
       " 1667: 509,\n",
       " 1672: 510,\n",
       " 1673: 511,\n",
       " 1674: 512,\n",
       " 1681: 513,\n",
       " 1686: 514,\n",
       " 1688: 515,\n",
       " 1691: 516,\n",
       " 1696: 517,\n",
       " 1697: 518,\n",
       " 1698: 519,\n",
       " 1711: 520,\n",
       " 1713: 521,\n",
       " 1714: 522,\n",
       " 1717: 523,\n",
       " 1718: 524,\n",
       " 1721: 525,\n",
       " 1722: 526,\n",
       " 1733: 527,\n",
       " 1736: 528,\n",
       " 1737: 529,\n",
       " 1738: 530,\n",
       " 1742: 531,\n",
       " 1744: 532,\n",
       " 1781: 533,\n",
       " 1782: 534,\n",
       " 1784: 535,\n",
       " 1786: 536,\n",
       " 1789: 537,\n",
       " 1796: 538,\n",
       " 1797: 539,\n",
       " 1798: 540,\n",
       " 1799: 541,\n",
       " 1806: 542,\n",
       " 1807: 543,\n",
       " 1808: 544,\n",
       " 1809: 545,\n",
       " 1811: 546,\n",
       " 1812: 547,\n",
       " 1814: 548,\n",
       " 1817: 549,\n",
       " 1819: 550,\n",
       " 1821: 551,\n",
       " 1822: 552,\n",
       " 1824: 553,\n",
       " 1832: 554,\n",
       " 1833: 555,\n",
       " 1836: 556,\n",
       " 1838: 557,\n",
       " 1839: 558,\n",
       " 1842: 559,\n",
       " 1843: 560,\n",
       " 1846: 561,\n",
       " 1847: 562,\n",
       " 1848: 563,\n",
       " 1856: 564,\n",
       " 1857: 565,\n",
       " 1861: 566,\n",
       " 1862: 567,\n",
       " 1863: 568,\n",
       " 1864: 569,\n",
       " 1866: 570,\n",
       " 1867: 571,\n",
       " 1869: 572,\n",
       " 1871: 573,\n",
       " 1872: 574,\n",
       " 1873: 575,\n",
       " 2031: 576,\n",
       " 2032: 577,\n",
       " 2034: 578,\n",
       " 2039: 579,\n",
       " 2047: 580,\n",
       " 2049: 581,\n",
       " 2057: 582,\n",
       " 2058: 583,\n",
       " 2063: 584,\n",
       " 2066: 585,\n",
       " 2071: 586,\n",
       " 2082: 587,\n",
       " 2087: 588,\n",
       " 2092: 589,\n",
       " 2097: 590,\n",
       " 2106: 591,\n",
       " 2111: 592,\n",
       " 2112: 593,\n",
       " 2113: 594,\n",
       " 2118: 595,\n",
       " 2162: 596,\n",
       " 2163: 597,\n",
       " 2164: 598,\n",
       " 2167: 599,\n",
       " 2169: 600,\n",
       " 2186: 601,\n",
       " 2187: 602,\n",
       " 2188: 603,\n",
       " 2193: 604,\n",
       " 2198: 605,\n",
       " 2199: 606,\n",
       " 1050781: 607,\n",
       " 1050782: 608,\n",
       " 1050783: 609,\n",
       " 1050784: 610,\n",
       " 2209: 611,\n",
       " 1050786: 612,\n",
       " 1050787: 613,\n",
       " 1050788: 614,\n",
       " 2213: 615,\n",
       " 2214: 616,\n",
       " 1050791: 617,\n",
       " 1050792: 618,\n",
       " 1050793: 619,\n",
       " 1050794: 620,\n",
       " 2218: 621,\n",
       " 2217: 622,\n",
       " 1050796: 623,\n",
       " 1050797: 624,\n",
       " 2221: 625,\n",
       " 1050798: 626,\n",
       " 2222: 627,\n",
       " 1050799: 628,\n",
       " 2223: 629,\n",
       " 2224: 630,\n",
       " 1050806: 631,\n",
       " 1050807: 632,\n",
       " 1050808: 633,\n",
       " 2232: 634,\n",
       " 1050809: 635,\n",
       " 1050811: 636,\n",
       " 1050812: 637,\n",
       " 1050813: 638,\n",
       " 1050814: 639,\n",
       " 2238: 640,\n",
       " 1050816: 641,\n",
       " 1050817: 642,\n",
       " 1050818: 643,\n",
       " 1050819: 644,\n",
       " 2237: 645,\n",
       " 1050821: 646,\n",
       " 1050822: 647,\n",
       " 1050823: 648,\n",
       " 1050824: 649,\n",
       " 2242: 650,\n",
       " 2244: 651,\n",
       " 2246: 652,\n",
       " 2247: 653,\n",
       " 2249: 654,\n",
       " 1050825: 655,\n",
       " 1050831: 656,\n",
       " 1050832: 657,\n",
       " 1050833: 658,\n",
       " 1050834: 659,\n",
       " 1050836: 660,\n",
       " 1050837: 661,\n",
       " 1050838: 662,\n",
       " 1050839: 663,\n",
       " 1050841: 664,\n",
       " 1050842: 665,\n",
       " 1050843: 666,\n",
       " 1050844: 667,\n",
       " 1050846: 668,\n",
       " 1050847: 669,\n",
       " 1050848: 670,\n",
       " 1050849: 671,\n",
       " 1050856: 672,\n",
       " 1050857: 673,\n",
       " 1050858: 674,\n",
       " 1050859: 675,\n",
       " 1050861: 676,\n",
       " 1050862: 677,\n",
       " 1050863: 678,\n",
       " 1050864: 679,\n",
       " 2288: 680,\n",
       " 1050866: 681,\n",
       " 1050867: 682,\n",
       " 1050868: 683,\n",
       " 1050869: 684,\n",
       " 2292: 685,\n",
       " 1050871: 686,\n",
       " 1050872: 687,\n",
       " 1050873: 688,\n",
       " 1050874: 689,\n",
       " 2293: 690,\n",
       " 2294: 691,\n",
       " 2296: 692,\n",
       " 2298: 693,\n",
       " 2306: 694,\n",
       " 2311: 695,\n",
       " 2312: 696,\n",
       " 2316: 697,\n",
       " 2317: 698,\n",
       " 2318: 699,\n",
       " 2323: 700,\n",
       " 1050906: 701,\n",
       " 1050907: 702,\n",
       " 1050908: 703,\n",
       " 1050909: 704,\n",
       " 2334: 705,\n",
       " 1050911: 706,\n",
       " 1050912: 707,\n",
       " 1050913: 708,\n",
       " 1050914: 709,\n",
       " 2336: 710,\n",
       " 1050916: 711,\n",
       " 1050917: 712,\n",
       " 1050918: 713,\n",
       " 1050919: 714,\n",
       " 2343: 715,\n",
       " 1050921: 716,\n",
       " 1050922: 717,\n",
       " 1050923: 718,\n",
       " 1050924: 719,\n",
       " 1050925: 720,\n",
       " 2346: 721,\n",
       " 2344: 722,\n",
       " 2348: 723,\n",
       " 2349: 724,\n",
       " 1050931: 725,\n",
       " 1050932: 726,\n",
       " 1050933: 727,\n",
       " 1050934: 728,\n",
       " 2356: 729,\n",
       " 1050936: 730,\n",
       " 1050937: 731,\n",
       " 2361: 732,\n",
       " 1050938: 733,\n",
       " 1050939: 734,\n",
       " 1050941: 735,\n",
       " 1050942: 736,\n",
       " 1050943: 737,\n",
       " 1050944: 738,\n",
       " 2368: 739,\n",
       " 1050946: 740,\n",
       " 1050947: 741,\n",
       " 1050948: 742,\n",
       " 1050949: 743,\n",
       " 2371: 744,\n",
       " 1050956: 745,\n",
       " 1050957: 746,\n",
       " 1050958: 747,\n",
       " 1050959: 748,\n",
       " 1050961: 749,\n",
       " 1050962: 750,\n",
       " 1050963: 751,\n",
       " 1050964: 752,\n",
       " 1050966: 753,\n",
       " 1050967: 754,\n",
       " 1050968: 755,\n",
       " 1050969: 756,\n",
       " 1050971: 757,\n",
       " 1050972: 758,\n",
       " 1050973: 759,\n",
       " 1050974: 760,\n",
       " 1050981: 761,\n",
       " 1050982: 762,\n",
       " 1050983: 763,\n",
       " 1050984: 764,\n",
       " 2408: 765,\n",
       " 1050986: 766,\n",
       " 1050987: 767,\n",
       " 1050988: 768,\n",
       " 1050989: 769,\n",
       " 2414: 770,\n",
       " 1050991: 771,\n",
       " 1050992: 772,\n",
       " 1050993: 773,\n",
       " 1050994: 774,\n",
       " 2418: 775,\n",
       " 1050996: 776,\n",
       " 1050997: 777,\n",
       " 1050998: 778,\n",
       " 1050999: 779,\n",
       " 2419: 780,\n",
       " 2439: 781,\n",
       " 2441: 782,\n",
       " 2442: 783,\n",
       " 2443: 784,\n",
       " 2449: 785,\n",
       " 1051031: 786,\n",
       " 1051032: 787,\n",
       " 1051033: 788,\n",
       " 1051034: 789,\n",
       " 2459: 790,\n",
       " 1051036: 791,\n",
       " 1051037: 792,\n",
       " 1051038: 793,\n",
       " 1051039: 794,\n",
       " 2461: 795,\n",
       " 1051041: 796,\n",
       " 1051042: 797,\n",
       " 1051043: 798,\n",
       " 2468: 799,\n",
       " 1051044: 800,\n",
       " 1051046: 801,\n",
       " 1051047: 802,\n",
       " 1051048: 803,\n",
       " 2473: 804,\n",
       " 1051049: 805,\n",
       " 2469: 806,\n",
       " 1051056: 807,\n",
       " 1051057: 808,\n",
       " 2482: 809,\n",
       " 2483: 810,\n",
       " 1051059: 811,\n",
       " 1051061: 812,\n",
       " 1051062: 813,\n",
       " 1051063: 814,\n",
       " 1051064: 815,\n",
       " 1051058: 816,\n",
       " 1051066: 817,\n",
       " 1051067: 818,\n",
       " 1051068: 819,\n",
       " 1051069: 820,\n",
       " 2486: 821,\n",
       " 1051071: 822,\n",
       " 1051072: 823,\n",
       " 1051073: 824,\n",
       " 1051074: 825,\n",
       " 2497: 826,\n",
       " 1051081: 827,\n",
       " 1051082: 828,\n",
       " 1051083: 829,\n",
       " 1051084: 830,\n",
       " 1051086: 831,\n",
       " 1051087: 832,\n",
       " 1051088: 833,\n",
       " 1051089: 834,\n",
       " 1051091: 835,\n",
       " 1051092: 836,\n",
       " 1051093: 837,\n",
       " 1051094: 838,\n",
       " 1051096: 839,\n",
       " 1051097: 840,\n",
       " 1051098: 841,\n",
       " 1051099: 842,\n",
       " 1051106: 843,\n",
       " 1051107: 844,\n",
       " 1051108: 845,\n",
       " 1051109: 846,\n",
       " 1051111: 847,\n",
       " 1051112: 848,\n",
       " 1051113: 849,\n",
       " 1051114: 850,\n",
       " 1051116: 851,\n",
       " 1051117: 852,\n",
       " 1051118: 853,\n",
       " 1051119: 854,\n",
       " 1051121: 855,\n",
       " 1051122: 856,\n",
       " 1051123: 857,\n",
       " 1051124: 858,\n",
       " 1051156: 859,\n",
       " 1051157: 860,\n",
       " 1051158: 861,\n",
       " 1051159: 862,\n",
       " 1051161: 863,\n",
       " 1051162: 864,\n",
       " 1051163: 865,\n",
       " 1051164: 866,\n",
       " 1051166: 867,\n",
       " 1051167: 868,\n",
       " 1051168: 869,\n",
       " 1051169: 870,\n",
       " 1051171: 871,\n",
       " 1051172: 872,\n",
       " 1051173: 873,\n",
       " 1051174: 874,\n",
       " 1051181: 875,\n",
       " 1051182: 876,\n",
       " 1051183: 877,\n",
       " 1051184: 878,\n",
       " 1051186: 879,\n",
       " 1051187: 880,\n",
       " 1051188: 881,\n",
       " 1051189: 882,\n",
       " 1051191: 883,\n",
       " 1051192: 884,\n",
       " 1051193: 885,\n",
       " 1051194: 886,\n",
       " 1051196: 887,\n",
       " 1051197: 888,\n",
       " 1051198: 889,\n",
       " 1051199: 890,\n",
       " 1051206: 891,\n",
       " 1051207: 892,\n",
       " 1051208: 893,\n",
       " 1051209: 894,\n",
       " 1051211: 895,\n",
       " 1051212: 896,\n",
       " 1051213: 897,\n",
       " 1051214: 898,\n",
       " 1051216: 899,\n",
       " 1051217: 900,\n",
       " 1051218: 901,\n",
       " 1051219: 902,\n",
       " 1051221: 903,\n",
       " 1051222: 904,\n",
       " 1051223: 905,\n",
       " 1051224: 906,\n",
       " 1051231: 907,\n",
       " 1051232: 908,\n",
       " 1051233: 909,\n",
       " 1051234: 910,\n",
       " 2656: 911,\n",
       " 1051236: 912,\n",
       " 1051237: 913,\n",
       " 1051238: 914,\n",
       " 1051239: 915,\n",
       " 2663: 916,\n",
       " 1051241: 917,\n",
       " 1051242: 918,\n",
       " 2666: 919,\n",
       " 1051243: 920,\n",
       " 1051244: 921,\n",
       " 1051246: 922,\n",
       " 1051247: 923,\n",
       " 1051248: 924,\n",
       " 2672: 925,\n",
       " 1051249: 926,\n",
       " 2674: 927,\n",
       " 2671: 928,\n",
       " 2681: 929,\n",
       " 2683: 930,\n",
       " 2684: 931,\n",
       " 2687: 932,\n",
       " 2689: 933,\n",
       " 2693: 934,\n",
       " 2696: 935,\n",
       " 2698: 936,\n",
       " 2699: 937,\n",
       " 2706: 938,\n",
       " 2709: 939,\n",
       " 2713: 940,\n",
       " 2717: 941,\n",
       " 2718: 942,\n",
       " 2721: 943,\n",
       " 2722: 944,\n",
       " 2723: 945,\n",
       " 2724: 946,\n",
       " 2731: 947,\n",
       " 2733: 948,\n",
       " 2734: 949,\n",
       " 2736: 950,\n",
       " 2737: 951,\n",
       " 2738: 952,\n",
       " 2743: 953,\n",
       " 2746: 954,\n",
       " 2747: 955,\n",
       " 2749: 956,\n",
       " 2781: 957,\n",
       " 2782: 958,\n",
       " 2784: 959,\n",
       " 2786: 960,\n",
       " 2787: 961,\n",
       " 2789: 962,\n",
       " 2791: 963,\n",
       " 2793: 964,\n",
       " 2794: 965,\n",
       " 2796: 966,\n",
       " 2797: 967,\n",
       " 2808: 968,\n",
       " 2809: 969,\n",
       " 2811: 970,\n",
       " 2813: 971,\n",
       " 2814: 972,\n",
       " 2816: 973,\n",
       " 2817: 974,\n",
       " 2818: 975,\n",
       " 2819: 976,\n",
       " 2821: 977,\n",
       " 2822: 978,\n",
       " 2823: 979,\n",
       " 2824: 980,\n",
       " 1051406: 981,\n",
       " 1051407: 982,\n",
       " 1051408: 983,\n",
       " 1051409: 984,\n",
       " 2834: 985,\n",
       " 1051411: 986,\n",
       " 1051412: 987,\n",
       " 1051413: 988,\n",
       " 1051414: 989,\n",
       " 2837: 990,\n",
       " 1051416: 991,\n",
       " 1051417: 992,\n",
       " 1051418: 993,\n",
       " 1051419: 994,\n",
       " 2841: 995,\n",
       " 1051421: 996,\n",
       " 1051422: 997,\n",
       " 1051423: 998,\n",
       " 1051424: 999,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    kmers = tf.Variable(tf.constant(0.0, shape=[kmer_count, 128]),\n",
    "                        trainable=False, name=\"kmers\")\n",
    "    \n",
    "    embedding_placeholder = tf.placeholder(tf.int32, [kmer_count, 128])\n",
    "    embedding_init = kmers.assign(embeddings)\n",
    "    \n",
    "    train_input = tf.placeholder(tf.int32, shape=[batch_size, 15]) \n",
    "    train_label = tf.placeholder(tf.int32, shape=[batch_size, 3])\n",
    "    \n",
    "    kmer_input = tf.nn.embedding_lookup(embeddings, train_input)\n",
    "    kmer_input_r = tf.reshape(kmer_input, [batch_size, -1])\n",
    "    \n",
    "    l1 = tf.layers.dense(kmer_input_r, n_hidden_1)\n",
    "    l2 = tf.layers.dense(l1, n_hidden_2)\n",
    "    logits = tf.layers.dense(l2, len(replicons_list))\n",
    "    \n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_prob = tf.nn.softmax(logits)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = train_label))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    acc = tf.metrics.accuracy(labels = tf.argmax(train_label, 1), predictions=pred_classes)\n",
    "\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=pred_classes,\n",
    "            loss=loss,\n",
    "            train_op=train,\n",
    "            eval_metric_ops={'accuracy': acc})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbatch = generate_training_batch(training_data, 1, window_size)\n",
    "len(tbatch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'packed:0' shape=(1, 1920) dtype=float32>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.load(\"embeddings_200000.npy\")\n",
    "\n",
    "def get_kmer_embeddings(kmers):\n",
    "    a = list() # numpy.empty(128 * 15)\n",
    "    for k in kmers:\n",
    "        a.append(embeddings[k])\n",
    "    return np.hstack(a)\n",
    "\n",
    "# training_data = load_fasta(filegen())\n",
    "get_kmer_embeddings(tbatch[0][0])\n",
    "\n",
    "tf.convert_to_tensor([tf.convert_to_tensor(get_kmer_embeddings(tbatch[0][0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repdict = dict()\n",
    "a = 0\n",
    "for i in replicons_list:\n",
    "    repdict[i] = a\n",
    "    a += 1\n",
    "\n",
    "def train_input_fn(data):\n",
    "    tbatch = generate_training_batch(data, 1, window_size)\n",
    "    dat = {'x': tf.convert_to_tensor([tf.convert_to_tensor(get_kmer_embeddings(tbatch[0][0]))])}\n",
    "    lab = tf.convert_to_tensor([repdict[tbatch[0][1]]])\n",
    "    return dat, lab\n",
    "\n",
    "def test_input_fn(data):\n",
    "    tbatch = generate_training_batch(data, 1, window_size)\n",
    "    dat = {'x': tf.convert_to_tensor([tf.convert_to_tensor(get_kmer_embeddings(tbatch[0][0]))])}\n",
    "    lab = tf.convert_to_tensor([repdict[tbatch[0][1]]])\n",
    "    return dat, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9xj4sya3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp9xj4sya3', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1920])]\n",
    "nn = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                hidden_units = [5000,500,50],\n",
    "                                activation_fn=tf.nn.relu,\n",
    "                                dropout=0.2,\n",
    "                                n_classes=len(replicons_list),\n",
    "                                optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found, generating new sequence: Rm1021.final.fasta.picklepickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.34785, step = 1\n",
      "INFO:tensorflow:global_step/sec: 28.5192\n",
      "INFO:tensorflow:loss = 0.0, step = 101 (3.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1805\n",
      "INFO:tensorflow:loss = 0.0, step = 201 (3.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4364\n",
      "INFO:tensorflow:loss = 0.0, step = 301 (3.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1645\n",
      "INFO:tensorflow:loss = 0.0, step = 401 (3.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2323\n",
      "INFO:tensorflow:loss = 0.0, step = 501 (3.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1659\n",
      "INFO:tensorflow:loss = 0.0, step = 601 (3.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8472\n",
      "INFO:tensorflow:loss = 0.0, step = 701 (3.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4099\n",
      "INFO:tensorflow:loss = 0.0, step = 801 (3.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2158\n",
      "INFO:tensorflow:loss = 0.0, step = 901 (3.966 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "Loading from pickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 793380.0, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 28.5237\n",
      "INFO:tensorflow:loss = 0.0, step = 1101 (3.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1447\n",
      "INFO:tensorflow:loss = 0.0, step = 1201 (3.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.064\n",
      "INFO:tensorflow:loss = 0.0, step = 1301 (3.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.166\n",
      "INFO:tensorflow:loss = 0.0, step = 1401 (3.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9298\n",
      "INFO:tensorflow:loss = 0.0, step = 1501 (3.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3651\n",
      "INFO:tensorflow:loss = 0.0, step = 1601 (3.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9429\n",
      "INFO:tensorflow:loss = 0.0, step = 1701 (3.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2238\n",
      "INFO:tensorflow:loss = 0.0, step = 1801 (3.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5102\n",
      "INFO:tensorflow:loss = 0.0, step = 1901 (3.635 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "File not found, generating new sequence: Rm41.final.fasta.picklepickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 7.42754e+06, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 28.8654\n",
      "INFO:tensorflow:loss = 0.0, step = 2101 (3.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6591\n",
      "INFO:tensorflow:loss = 0.0, step = 2201 (3.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4739\n",
      "INFO:tensorflow:loss = 0.0, step = 2301 (3.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.503\n",
      "INFO:tensorflow:loss = 0.0, step = 2401 (3.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0401\n",
      "INFO:tensorflow:loss = 0.0, step = 2501 (4.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1978\n",
      "INFO:tensorflow:loss = 0.0, step = 2601 (3.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6108\n",
      "INFO:tensorflow:loss = 0.0, step = 2701 (3.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7816\n",
      "INFO:tensorflow:loss = 0.0, step = 2801 (4.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3176\n",
      "INFO:tensorflow:loss = 0.0, step = 2901 (3.799 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "File not found, generating new sequence: T073.final.fasta.picklepickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-3000\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 3001\n",
      "INFO:tensorflow:global_step/sec: 28.641\n",
      "INFO:tensorflow:loss = 0.0, step = 3101 (3.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5854\n",
      "INFO:tensorflow:loss = 0.0, step = 3201 (3.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1969\n",
      "INFO:tensorflow:loss = 0.0, step = 3301 (3.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2528\n",
      "INFO:tensorflow:loss = 0.0, step = 3401 (3.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6515\n",
      "INFO:tensorflow:loss = 0.0, step = 3501 (3.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.7999\n",
      "INFO:tensorflow:loss = 0.0, step = 3601 (3.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.958\n",
      "INFO:tensorflow:loss = 0.0, step = 3701 (3.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3693\n",
      "INFO:tensorflow:loss = 0.0, step = 3801 (3.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4087\n",
      "INFO:tensorflow:loss = 0.0, step = 3901 (3.648 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "File not found, generating new sequence: Reference.final.fasta.picklepickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.30246e+07, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 27.8188\n",
      "INFO:tensorflow:loss = 0.0, step = 4101 (3.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9241\n",
      "INFO:tensorflow:loss = 0.0, step = 4201 (3.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1218\n",
      "INFO:tensorflow:loss = 0.0, step = 4301 (3.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7197\n",
      "INFO:tensorflow:loss = 0.0, step = 4401 (3.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5138\n",
      "INFO:tensorflow:loss = 0.0, step = 4501 (3.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3232\n",
      "INFO:tensorflow:loss = 0.0, step = 4601 (3.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6952\n",
      "INFO:tensorflow:loss = 0.0, step = 4701 (3.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2572\n",
      "INFO:tensorflow:loss = 0.0, step = 4801 (3.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8174\n",
      "INFO:tensorflow:loss = 0.0, step = 4901 (3.595 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "File not found, generating new sequence: USDA1021.final.fasta.picklepickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.39048e+06, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 27.3099\n",
      "INFO:tensorflow:loss = 0.0, step = 5101 (3.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.7445\n",
      "INFO:tensorflow:loss = 0.0, step = 5201 (3.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1552\n",
      "INFO:tensorflow:loss = 0.0, step = 5301 (3.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.151\n",
      "INFO:tensorflow:loss = 0.0, step = 5401 (3.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2557\n",
      "INFO:tensorflow:loss = 0.0, step = 5501 (3.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.198\n",
      "INFO:tensorflow:loss = 0.0, step = 5601 (3.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1295\n",
      "INFO:tensorflow:loss = 0.0, step = 5701 (3.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2426\n",
      "INFO:tensorflow:loss = 0.0, step = 5801 (3.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2409\n",
      "INFO:tensorflow:loss = 0.0, step = 5901 (3.420 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "File not found, generating new sequence: GR4.final.fasta.picklepickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.47766e+06, step = 6001\n",
      "INFO:tensorflow:global_step/sec: 28.9916\n",
      "INFO:tensorflow:loss = 0.0, step = 6101 (3.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4964\n",
      "INFO:tensorflow:loss = 0.0, step = 6201 (3.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9604\n",
      "INFO:tensorflow:loss = 0.0, step = 6301 (4.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6714\n",
      "INFO:tensorflow:loss = 0.0, step = 6401 (4.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4299\n",
      "INFO:tensorflow:loss = 0.0, step = 6501 (4.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7221\n",
      "INFO:tensorflow:loss = 0.0, step = 6601 (3.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8546\n",
      "INFO:tensorflow:loss = 0.0, step = 6701 (4.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2735\n",
      "INFO:tensorflow:loss = 0.0, step = 6801 (4.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8662\n",
      "INFO:tensorflow:loss = 0.0, step = 6901 (3.722 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "File not found, generating new sequence: AK83.final.fasta.picklepickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-7000\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.28266e+06, step = 7001\n",
      "INFO:tensorflow:global_step/sec: 26.711\n",
      "INFO:tensorflow:loss = 0.0, step = 7101 (3.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4335\n",
      "INFO:tensorflow:loss = 0.0, step = 7201 (3.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4788\n",
      "INFO:tensorflow:loss = 0.0, step = 7301 (3.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7374\n",
      "INFO:tensorflow:loss = 0.0, step = 7401 (3.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5929\n",
      "INFO:tensorflow:loss = 0.0, step = 7501 (3.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3341\n",
      "INFO:tensorflow:loss = 0.0, step = 7601 (3.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.132\n",
      "INFO:tensorflow:loss = 0.0, step = 7701 (3.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9661\n",
      "INFO:tensorflow:loss = 0.0, step = 7801 (3.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0794\n",
      "INFO:tensorflow:loss = 0.0, step = 7901 (3.561 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "File not found, generating new sequence: KH35c.final.fasta.picklepickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-8000\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 136417.0, step = 8001\n",
      "INFO:tensorflow:global_step/sec: 28.9184\n",
      "INFO:tensorflow:loss = 0.0, step = 8101 (3.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2907\n",
      "INFO:tensorflow:loss = 0.0, step = 8201 (3.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2081\n",
      "INFO:tensorflow:loss = 0.0, step = 8301 (3.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1521\n",
      "INFO:tensorflow:loss = 0.0134618, step = 8401 (3.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6433\n",
      "INFO:tensorflow:loss = 0.0, step = 8501 (3.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.274\n",
      "INFO:tensorflow:loss = 0.0, step = 8601 (3.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8289\n",
      "INFO:tensorflow:loss = 0.0036066, step = 8701 (3.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3224\n",
      "INFO:tensorflow:loss = 0.0, step = 8801 (3.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6226\n",
      "INFO:tensorflow:loss = 0.0, step = 8901 (3.494 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "Loading from pickle\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-9000\n",
      "INFO:tensorflow:Saving checkpoints for 9001 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:loss = 120083.0, step = 9001\n",
      "INFO:tensorflow:global_step/sec: 28.8553\n",
      "INFO:tensorflow:loss = 0.0, step = 9101 (3.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9712\n",
      "INFO:tensorflow:loss = 0.0, step = 9201 (3.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8276\n",
      "INFO:tensorflow:loss = 0.0, step = 9301 (3.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2405\n",
      "INFO:tensorflow:loss = 0.0, step = 9401 (3.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2947\n",
      "INFO:tensorflow:loss = 0.0, step = 9501 (3.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1584\n",
      "INFO:tensorflow:loss = 0.0, step = 9601 (3.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8475\n",
      "INFO:tensorflow:loss = 0.0, step = 9701 (3.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1502\n",
      "INFO:tensorflow:loss = 0.0, step = 9801 (3.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.7327\n",
      "INFO:tensorflow:loss = 0.0, step = 9901 (3.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmp9xj4sya3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(10):\n",
    "    training_data = load_fasta(filegen())\n",
    "    tfn = functools.partial(train_input_fn, training_data)\n",
    "    nn.train(input_fn=tfn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found, generating new sequence: USDA1106.final.fasta.picklepickle\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-20-22:16:29\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9xj4sya3/model.ckpt-10000\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-20-22:16:29\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 1.0, average_loss = 0.0, global_step = 10000, loss = 0.0\n",
      "\n",
      "Test Accuracy: 1.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = load_fasta(filegen())\n",
    "tfn = functools.partial(train_input_fn, training_data)\n",
    "accuracy_score = nn.evaluate(input_fn=tfn, steps=10)['accuracy']\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run() missing 1 required positional argument: 'fetches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-0eef4d8744d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: run() missing 1 required positional argument: 'fetches'"
     ]
    }
   ],
   "source": [
    "tfn = functools.partial(train_input_fn, training_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
